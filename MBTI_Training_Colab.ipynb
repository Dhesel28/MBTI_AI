{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Personality Prediction - Model Training\n",
    "\n",
    "This notebook trains 4 transformer models on 4 MBTI traits (16 total training runs).\n",
    "\n",
    "**Features:**\n",
    "- Automatic checkpointing after each model/trait\n",
    "- Resume from where you left off if disconnected\n",
    "- Saves best models to Google Drive\n",
    "- Progress tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for saving checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project folder\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/MBTI_AI'\n",
    "CHECKPOINT_DIR = f'{PROJECT_DIR}/checkpoints'\n",
    "MODEL_DIR = f'{PROJECT_DIR}/models'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"Project directory: {PROJECT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your dataset (mbti_1.csv)\n",
    "# Option 1: Upload from local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Check if dataset already exists in Drive\n",
    "DATASET_PATH = f'{PROJECT_DIR}/mbti_1.csv'\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(\"Please upload mbti_1.csv\")\n",
    "    uploaded = files.upload()\n",
    "    # Move to project directory\n",
    "    !mv mbti_1.csv {DATASET_PATH}\n",
    "else:\n",
    "    print(f\"Dataset found at {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "DEBERTA_MODEL_NAME = 'microsoft/deberta-v3-small'\n",
    "\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "\n",
    "# Learning rates\n",
    "BASIC_LR = 2e-5\n",
    "BERT_DEEP_HEAD_LR = 1e-4\n",
    "BERT_DEEP_BERT_LR = 1e-5\n",
    "BERT_DEEP_DROPOUT = 0.55\n",
    "DEBERTA_DEEP_HEAD_LR = 1e-4\n",
    "DEBERTA_DEEP_BERT_LR = 1e-5\n",
    "DEBERTA_DEEP_DROPOUT = 0.55\n",
    "ABLATION_HEAD_LR = 1e-4\n",
    "ABLATION_BERT_LR = 1e-5\n",
    "ABLATION_DROPOUT = 0.55\n",
    "\n",
    "# Traits to train\n",
    "TRAITS = ['is_I', 'is_N', 'is_T', 'is_P']\n",
    "TRAIT_NAMES = {\n",
    "    'is_I': 'Mind (I/E)', \n",
    "    'is_N': 'Energy (N/S)', \n",
    "    'is_T': 'Nature (T/F)', \n",
    "    'is_P': 'Tactics (P/J)'\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "MODEL_NAMES = [\n",
    "    'Basic_BERT',\n",
    "    'BERT_Deep_Head',\n",
    "    'DeBERTa_Deep_Head',\n",
    "    'DeBERTa_AttnPool_Deep'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('|||', ' ')\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def load_and_preprocess_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['cleaned_posts'] = df['posts'].apply(clean_text)\n",
    "    df['is_I'] = df['type'].apply(lambda x: 1 if x[0] == 'I' else 0)\n",
    "    df['is_N'] = df['type'].apply(lambda x: 1 if x[1] == 'N' else 0)\n",
    "    df['is_T'] = df['type'].apply(lambda x: 1 if x[2] == 'T' else 0)\n",
    "    df['is_P'] = df['type'].apply(lambda x: 1 if x[3] == 'P' else 0)\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df = load_and_preprocess_data(DATASET_PATH)\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"\\nMBTI Type distribution:\")\n",
    "print(df['type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBTITraitDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_very_deep_head(input_size, output_size, hidden_sizes, dropout_rate):\n",
    "    \"\"\"Creates a sequential head with multiple linear layers.\"\"\"\n",
    "    layers = []\n",
    "    current_size = input_size\n",
    "    for hidden_size in hidden_sizes:\n",
    "        layers.extend([\n",
    "            nn.Linear(current_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ])\n",
    "        current_size = hidden_size\n",
    "    layers.append(nn.Linear(current_size, output_size))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class BaselineBERTClassifier(nn.Module):\n",
    "    \"\"\"Model 1: Basic BERT\"\"\"\n",
    "    def __init__(self, n_out=1, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_out)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class BERTDeepHeadClassifier(nn.Module):\n",
    "    \"\"\"Model 2: BERT with very deep head (6 linear layers)\"\"\"\n",
    "    def __init__(self, n_out=1, dropout_rate=BERT_DEEP_DROPOUT):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        hidden_sizes = [512, 256, 128, 64, 32]\n",
    "        self.head = create_very_deep_head(bert_hidden_size, n_out, hidden_sizes, dropout_rate)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DeBERTaClassifier(nn.Module):\n",
    "    \"\"\"Model 3: DeBERTa with very deep head (6 linear layers, CLS pooling)\"\"\"\n",
    "    def __init__(self, n_out=1, dropout_rate=DEBERTA_DEEP_DROPOUT):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(DEBERTA_MODEL_NAME)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        hidden_sizes = [512, 256, 128, 64, 32]\n",
    "        self.head = create_very_deep_head(bert_hidden_size, n_out, hidden_sizes, dropout_rate)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attention_net = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        scores = self.attention_net(hidden_states)\n",
    "        scores.masked_fill_(attention_mask.unsqueeze(-1) == 0, -float('inf'))\n",
    "        attn_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.sum(attn_weights * hidden_states, dim=1)\n",
    "        return context\n",
    "\n",
    "\n",
    "class DeBERTaAblationModel(nn.Module):\n",
    "    \"\"\"Model 4: DeBERTa + Attention Pooling + Very Deep Head\"\"\"\n",
    "    def __init__(self, n_out=1, dropout_rate=ABLATION_DROPOUT):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(DEBERTA_MODEL_NAME)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        self.attention_pooling = AttentionPooling(bert_hidden_size)\n",
    "        hidden_sizes = [512, 256, 128, 64, 32]\n",
    "        self.head = create_very_deep_head(bert_hidden_size, n_out, hidden_sizes, dropout_rate)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = self.attention_pooling(last_hidden_state, attention_mask)\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(data_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_labels, all_probs, all_preds = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.flatten())\n",
    "            all_preds.extend(preds.flatten())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    try:\n",
    "        auc_roc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc_roc = 0.5\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'AUC-ROC': auc_roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checkpoint Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress_file():\n",
    "    return f'{CHECKPOINT_DIR}/training_progress.json'\n",
    "\n",
    "def load_progress():\n",
    "    \"\"\"Load training progress from checkpoint.\"\"\"\n",
    "    progress_file = get_progress_file()\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {'completed': [], 'results': {}}\n",
    "\n",
    "def save_progress(progress):\n",
    "    \"\"\"Save training progress to checkpoint.\"\"\"\n",
    "    progress_file = get_progress_file()\n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump(progress, f, indent=2)\n",
    "\n",
    "def is_completed(trait, model_name, progress):\n",
    "    \"\"\"Check if a trait/model combination is already trained.\"\"\"\n",
    "    key = f\"{trait}_{model_name}\"\n",
    "    return key in progress['completed']\n",
    "\n",
    "def mark_completed(trait, model_name, metrics, progress):\n",
    "    \"\"\"Mark a trait/model combination as completed.\"\"\"\n",
    "    key = f\"{trait}_{model_name}\"\n",
    "    progress['completed'].append(key)\n",
    "    progress['results'][key] = metrics\n",
    "    save_progress(progress)\n",
    "\n",
    "def save_model(model, trait, model_name):\n",
    "    \"\"\"Save trained model.\"\"\"\n",
    "    path = f\"{MODEL_DIR}/{trait}_{model_name}.pt\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Load existing progress\n",
    "progress = load_progress()\n",
    "print(f\"Completed: {len(progress['completed'])}/16 training runs\")\n",
    "if progress['completed']:\n",
    "    print(f\"Already completed: {progress['completed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizers\n",
    "print(\"Loading tokenizers...\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(DEBERTA_MODEL_NAME)\n",
    "print(\"Tokenizers loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, trait, df_train, df_val, progress):\n",
    "    \"\"\"Train a single model on a single trait.\"\"\"\n",
    "    \n",
    "    # Check if already completed\n",
    "    if is_completed(trait, model_name, progress):\n",
    "        print(f\"\\n[SKIP] {model_name} on {TRAIT_NAMES[trait]} - Already completed\")\n",
    "        return progress['results'][f\"{trait}_{model_name}\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name} on {TRAIT_NAMES[trait]}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Select tokenizer and create data loaders\n",
    "    if 'BERT' in model_name and 'DeBERTa' not in model_name:\n",
    "        tokenizer = bert_tokenizer\n",
    "    else:\n",
    "        tokenizer = deberta_tokenizer\n",
    "    \n",
    "    train_dataset = MBTITraitDataset(df_train['cleaned_posts'].values, df_train[trait].values, tokenizer, MAX_LEN)\n",
    "    val_dataset = MBTITraitDataset(df_val['cleaned_posts'].values, df_val[trait].values, tokenizer, MAX_LEN)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Create model\n",
    "    if model_name == 'Basic_BERT':\n",
    "        model = BaselineBERTClassifier().to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=BASIC_LR, correct_bias=False)\n",
    "        total_steps = len(train_loader) * EPOCHS\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        use_epoch_scheduler = False\n",
    "        \n",
    "    elif model_name == 'BERT_Deep_Head':\n",
    "        model = BERTDeepHeadClassifier().to(device)\n",
    "        optimizer = AdamW([\n",
    "            {\"params\": model.bert.parameters(), \"lr\": BERT_DEEP_BERT_LR},\n",
    "            {\"params\": model.head.parameters(), \"lr\": BERT_DEEP_HEAD_LR}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=EPOCHS)\n",
    "        use_epoch_scheduler = True\n",
    "        \n",
    "    elif model_name == 'DeBERTa_Deep_Head':\n",
    "        model = DeBERTaClassifier().to(device)\n",
    "        optimizer = AdamW([\n",
    "            {\"params\": model.bert.parameters(), \"lr\": DEBERTA_DEEP_BERT_LR},\n",
    "            {\"params\": model.head.parameters(), \"lr\": DEBERTA_DEEP_HEAD_LR}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=EPOCHS)\n",
    "        use_epoch_scheduler = True\n",
    "        \n",
    "    elif model_name == 'DeBERTa_AttnPool_Deep':\n",
    "        model = DeBERTaAblationModel().to(device)\n",
    "        optimizer = AdamW([\n",
    "            {\"params\": model.bert.parameters(), \"lr\": ABLATION_BERT_LR},\n",
    "            {\"params\": model.attention_pooling.parameters(), \"lr\": ABLATION_HEAD_LR},\n",
    "            {\"params\": model.head.parameters(), \"lr\": ABLATION_HEAD_LR}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=EPOCHS)\n",
    "        use_epoch_scheduler = True\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "    best_f1 = 0\n",
    "    best_metrics = {}\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "        \n",
    "        if use_epoch_scheduler:\n",
    "            train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler=None)\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device, scheduler=scheduler)\n",
    "        \n",
    "        metrics = eval_model(model, val_loader, device)\n",
    "        print(f\"Val F1: {metrics['F1']:.4f} | Val Acc: {metrics['Accuracy']:.4f} | Val AUC: {metrics['AUC-ROC']:.4f}\")\n",
    "        \n",
    "        if metrics['F1'] > best_f1:\n",
    "            best_f1 = metrics['F1']\n",
    "            best_metrics = metrics.copy()\n",
    "            # Save best model\n",
    "            save_model(model, trait, model_name)\n",
    "    \n",
    "    # Mark as completed and save progress\n",
    "    mark_completed(trait, model_name, best_metrics, progress)\n",
    "    print(f\"\\nBest F1 for {model_name} on {TRAIT_NAMES[trait]}: {best_f1:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop with checkpointing\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING TRAINING - 4 Models x 4 Traits = 16 Training Runs\")\n",
    "print(\"Progress is saved after each model. You can resume if disconnected.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for trait in TRAITS:\n",
    "    trait_name = TRAIT_NAMES[trait]\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"### TRAIT: {trait_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    # Split data for this trait\n",
    "    df_train, df_val = train_test_split(\n",
    "        df, test_size=0.1, random_state=42, stratify=df[trait]\n",
    "    )\n",
    "    print(f\"Train: {len(df_train)}, Val: {len(df_val)}\")\n",
    "    \n",
    "    for model_name in MODEL_NAMES:\n",
    "        metrics = train_model(model_name, trait, df_train, df_val, progress)\n",
    "        all_results[(trait_name, model_name)] = metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL COMPARISON REPORT\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Load all results from progress file\n",
    "progress = load_progress()\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_data = []\n",
    "for key, metrics in progress['results'].items():\n",
    "    trait, model = key.rsplit('_', 1)[0], key.split('_')[-1]\n",
    "    # Reconstruct proper names\n",
    "    for t in TRAITS:\n",
    "        if key.startswith(t):\n",
    "            trait = TRAIT_NAMES[t]\n",
    "            model = key[len(t)+1:]\n",
    "            break\n",
    "    results_data.append({\n",
    "        'Trait': trait,\n",
    "        'Model': model,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "# Display\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "results_csv_path = f\"{PROJECT_DIR}/final_results.csv\"\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"\\nResults saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model per trait\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST MODEL PER TRAIT (by F1 Score)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for trait in TRAIT_NAMES.values():\n",
    "    trait_results = results_df[results_df['Trait'] == trait]\n",
    "    if len(trait_results) > 0:\n",
    "        best_idx = trait_results['F1'].idxmax()\n",
    "        best = trait_results.loc[best_idx]\n",
    "        print(f\"{trait}: {best['Model']} (F1: {best['F1']:.4f}, Acc: {best['Accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved models\n",
    "print(\"Saved models:\")\n",
    "for f in os.listdir(MODEL_DIR):\n",
    "    if f.endswith('.pt'):\n",
    "        size_mb = os.path.getsize(f\"{MODEL_DIR}/{f}\") / (1024*1024)\n",
    "        print(f\"  - {f} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download a specific model\n",
    "# from google.colab import files\n",
    "# files.download(f\"{MODEL_DIR}/is_I_Basic_BERT.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
